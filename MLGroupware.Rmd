---
title: "MLGroupware"
author: "John Hoegger"
date: "Saturday, December 20, 2014"
output: html_document
---

### Machine Learning Project 
#### Johns Hopkins University (Coursera)
####
Background
----------
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

My goal of this project is to use data from accelerometers on the belt, forearm, arm and dumbell of 6 participants to predict how well they were performing weight lifting.  

Six young health participants were asked to perform one set of 10 repetitions of barbell lifts correctly and incorrectly in 5 different ways. These were labeled as:
1. Exactly according to the specification   (Class A)
2. Throwing the elbows to the front         (Class B)
3. Lifting the dumbbell only halfway        (Class C)
4. Lowering the dumbbell only halfway       (Class D) 
5. Throwing the hips to the front           (Class E)

More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

The training data is available here: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data is available here: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


####Load the libraries
```{r}
library(caret)
library(randomForest)
```

####Load the data
Remove the first column, as it is an index. The last column in the test data is also an index that can be removed
```{r}
training <- read.csv("pml-training.csv", header=TRUE, na.strings=c("NA","")) 
testing <- read.csv("pml-testing.csv", header=TRUE, na.strings=c("NA",""))

training <- training[,-1]
testing  <- testing [,-1]
testing  <- testing [,-ncol(testing)]
```

subset the data to allow for cross validation with 30% of the data
```{r}
set.seed(111)
inTrain <- createDataPartition(y = training$classe, p = 0.7, list=FALSE)
training <- training[inTrain,]
validate <- training[-inTrain,]
```

From looking at the data I noticed that there are a lot of columns that mainly contain NAs. These columns will not make good predictors and can be removed, which reduces the total number of columns that we need to work with. There are a lot of columns that contain 19216 NAs out of the total 19622 obersations. I will exclude all columns that have more than 90% NAs.

```{r}
cutOffThreshold <- 0.9 * nrow(training)
selectedColumns <- c((colSums(!is.na(training[,-ncol(training)])) 
                    >= cutOffThreshold))

training   <-  training[,selectedColumns]
validate <- validate[,selectedColumns]
testing <- testing[,selectedColumns]
```

This has reduced the number of columns from 160 down to just 59

###
###Selecting the Model
I decided that I would use Random Forest for the training model. I have set a seed
so that the results can be reproducible. 

Using Random Forest on nearly 15,000 observations and 59 variables takes a few minutes to run 

```{r}
modFit <- randomForest(classe~.,data=training)
modFit

predVal <- predict(modFit, validate)
confusionMatrix(predVal, validate$classe)

varImpPlot(modFit, nrow(modFit$importance))
```

###Sample Error
    Accuracy : 1          
    95% CI : (0.9991, 1)
    Sensitivity & Specificity are 1 in each class

###Test Data
Now predict using the test data
```{r}
testing <- rbind(training[2,-ncol(training)], testing)
predTest <- predict(modFit, testing[-1,])
predTest
```





