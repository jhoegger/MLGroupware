{"name":"Mlgroupware","tagline":"This is a machine learning project for predicting how well 6 participants did weight lifting exercises using a dataset from Groupware","body":"---\r\ntitle: \"MLGroupware\"\r\nauthor: \"John Hoegger\"\r\ndate: \"Saturday, December 20, 2014\"\r\noutput: html_document\r\n---\r\n\r\n### Machine Learning Project \r\n#### Johns Hopkins University (Coursera)\r\n####\r\nBackground\r\n----------\r\nUsing devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. \r\n\r\nMy goal of this project is to use data from accelerometers on the belt, forearm, arm and dumbell of 6 participants to predict how well they were performing weight lifting.  \r\n\r\nSix young health participants were asked to perform one set of 10 repetitions of barbell lifts correctly and incorrectly in 5 different ways. These were labeled as:\r\n1. Exactly according to the specification   (Class A)\r\n2. Throwing the elbows to the front         (Class B)\r\n3. Lifting the dumbbell only halfway        (Class C)\r\n4. Lowering the dumbbell only halfway       (Class D) \r\n5. Throwing the hips to the front           (Class E)\r\n\r\nMore information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). \r\n\r\nThe training data is available here: \r\nhttps://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\r\n\r\nThe test data is available here: \r\nhttps://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\r\n\r\n\r\n####Load the libraries\r\n```{r}\r\nlibrary(caret)\r\nlibrary(randomForest)\r\n```\r\n\r\n####Load the data\r\nRemove the first column, as it is an index. The last column in the test data is also an index that can be removed\r\n```{r}\r\ntraining <- read.csv(\"pml-training.csv\", header=TRUE, na.strings=c(\"NA\",\"\")) \r\ntesting <- read.csv(\"pml-testing.csv\", header=TRUE, na.strings=c(\"NA\",\"\"))\r\n\r\ntraining <- training[,-1]\r\ntesting  <- testing [,-1]\r\ntesting  <- testing [,-ncol(testing)]\r\n```\r\n\r\nsubset the data to allow for cross validation with 30% of the data\r\n```{r}\r\nset.seed(111)\r\ninTrain <- createDataPartition(y = training$classe, p = 0.7, list=FALSE)\r\ntraining <- training[inTrain,]\r\nvalidate <- training[-inTrain,]\r\n```\r\n\r\nFrom looking at the data I noticed that there are a lot of columns that mainly contain NAs. These columns will not make good predictors and can be removed, which reduces the total number of columns that we need to work with. There are a lot of columns that contain 19216 NAs out of the total 19622 obersations. I will exclude all columns that have more than 90% NAs.\r\n\r\n```{r}\r\ncutOffThreshold <- 0.9 * nrow(training)\r\nselectedColumns <- c((colSums(!is.na(training[,-ncol(training)])) \r\n                    >= cutOffThreshold))\r\n\r\ntraining   <-  training[,selectedColumns]\r\nvalidate <- validate[,selectedColumns]\r\ntesting <- testing[,selectedColumns]\r\n```\r\n\r\nThis has reduced the number of columns from 160 down to just 59\r\n\r\n###\r\n###Selecting the Model\r\nI decided that I would use Random Forest for the training model. I have set a seed\r\nso that the results can be reproducible. \r\n\r\nUsing Random Forest on nearly 15,000 observations and 59 variables takes a few minutes to run \r\n\r\n```{r}\r\nmodFit <- randomForest(classe~.,data=training)\r\nmodFit\r\n\r\npredVal <- predict(modFit, validate)\r\nconfusionMatrix(predVal, validate$classe)\r\n\r\nvarImpPlot(modFit, nrow(modFit$importance))\r\n```\r\n\r\n###Sample Error\r\n    Accuracy : 1          \r\n    95% CI : (0.9991, 1)\r\n    Sensitivity & Specificity are 1 in each class\r\n\r\n###Test Data\r\nNow predict using the test data\r\n```{r}\r\ntesting <- rbind(training[2,-ncol(training)], testing)\r\npredTest <- predict(modFit, testing[-1,])\r\npredTest\r\n```\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}